#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ - Faster Whisper + VAD ê¸°ë°˜
ìŠ¤íŠ¸ë¦¬ë° ìŒì„± ì¸ì‹ì„ ìœ„í•œ ê³ ì„±ëŠ¥ ì„œë¹„ìŠ¤
"""

import asyncio
import time
import tempfile
import os
from typing import Optional, Dict, Any, AsyncGenerator
from dataclasses import dataclass
from faster_whisper import WhisperModel
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class AudioChunk:
    """WebM ì˜¤ë””ì˜¤ ì²­í¬ ë°ì´í„° í´ë˜ìŠ¤"""
    data: str  # WebM íŒŒì¼ ê²½ë¡œ
    sample_rate: int
    timestamp: float
    is_final: bool = False

@dataclass
class TranscriptionResult:
    """ì „ì‚¬ ê²°ê³¼ í´ë˜ìŠ¤"""
    text: str
    confidence: float
    is_final: bool
    timestamp: float
    processing_time: float

# VAD í´ë˜ìŠ¤ ì œê±° - Faster Whisper ë‚´ì¥ VAD ì‚¬ìš©

class StreamingSTTService:
    """ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self,
                 model_size: str = "base",
                 device: str = "auto",
                 compute_type: str = "int8"):
        """
        STT ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            model_size: Whisper ëª¨ë¸ í¬ê¸° ("tiny", "base", "small", "medium", "large-v3")
            device: ë””ë°”ì´ìŠ¤ ("cpu", "cuda", "auto")
            compute_type: ê³„ì‚° íƒ€ì… ("int8", "float16", "float32")
        """
        self.model_size = model_size
        self.device = self._get_device(device)
        self.compute_type = compute_type

        # Faster Whisper ëª¨ë¸ ë¡œë“œ
        self.model: Optional[WhisperModel] = None

        # ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ ì„¤ì •
        self.chunk_duration = 1.0  # ì´ˆ
        self.overlap_duration = 0.3  # ì´ˆ (ì²­í¬ ê°„ ê²¹ì¹¨)
        self.sample_rate = 16000
        self.min_chunk_length = 0.5  # ìµœì†Œ ì²­í¬ ê¸¸ì´ (ì´ˆ)

        # ìƒíƒœ ê´€ë¦¬
        self.is_initialized = False
        self.transcription_history = []

        # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ í
        self.audio_queue = asyncio.Queue()
        self.result_queue = asyncio.Queue()

        logger.info(f"StreamingSTT ì´ˆê¸°í™”: {model_size} on {self.device}")

    def _get_device(self, device: str) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        if device == "auto":
            try:
                import torch
                return "cuda" if torch.cuda.is_available() else "cpu"
            except ImportError:
                return "cpu"
        return device

    async def initialize(self):
        """ëª¨ë¸ ë¹„ë™ê¸° ì´ˆê¸°í™”"""
        if self.is_initialized:
            return

        try:
            logger.info(f"Faster Whisper ëª¨ë¸ ë¡œë”© ì¤‘... ({self.model_size})")
            self.model = WhisperModel(
                self.model_size,
                device=self.device,
                compute_type=self.compute_type
            )
            self.is_initialized = True
            logger.info("âœ… Faster Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def add_audio_chunk(self, audio_data: bytes, timestamp: float = None) -> None:
        """
        WebM ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€ (ë™ê¸° ë©”ì†Œë“œ)

        Args:
            audio_data: WebM ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        """
        if timestamp is None:
            timestamp = time.time()

        try:
            # WebM ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ Faster Whisperì— ì§ì ‘ ì „ë‹¬
            with tempfile.NamedTemporaryFile(delete=False, suffix='.webm') as temp_file:
                temp_file.write(audio_data)
                temp_file_path = temp_file.name

            chunk = AudioChunk(
                data=temp_file_path,  # íŒŒì¼ ê²½ë¡œë¥¼ ì €ì¥
                sample_rate=self.sample_rate,
                timestamp=timestamp
            )

            # ë¹„ë™ê¸° íì— ì¶”ê°€ (ë…¼ë¸”ë¡œí‚¹)
            try:
                self.audio_queue.put_nowait(chunk)
            except asyncio.QueueFull:
                logger.warning("ì˜¤ë””ì˜¤ íê°€ ê°€ë“ì°¸ - ì²­í¬ ë“œë¡­")

        except Exception as e:
            logger.error(f"WebM ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    async def transcribe_chunk(self, audio_chunk: AudioChunk) -> Optional[TranscriptionResult]:
        """
        ë‹¨ì¼ WebM ì˜¤ë””ì˜¤ ì²­í¬ ì „ì‚¬

        Args:
            audio_chunk: WebM ì˜¤ë””ì˜¤ ì²­í¬ (íŒŒì¼ ê²½ë¡œ í¬í•¨)

        Returns:
            TranscriptionResult ë˜ëŠ” None
        """
        if not self.is_initialized or not self.model:
            await self.initialize()

        start_time = time.time()
        webm_file_path = audio_chunk.data

        try:
            # Faster Whisperë¡œ WebM íŒŒì¼ ì§ì ‘ ì „ì‚¬
            segments, info = self.model.transcribe(
                webm_file_path,
                language="ko",
                beam_size=1,  # ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ beam_size ê°ì†Œ
                word_timestamps=False,
                vad_filter=True,  # Faster Whisper ë‚´ì¥ VAD ì‚¬ìš©
                condition_on_previous_text=False  # ë…ë¦½ì ì¸ ì²­í¬ ì²˜ë¦¬
            )

            # ê²°ê³¼ í•©ì¹˜ê¸°
            text_parts = []
            total_confidence = 0
            segment_count = 0

            for segment in segments:
                text_parts.append(segment.text)
                # avg_logprobë¥¼ confidenceë¡œ ë³€í™˜ (-1~0 ë²”ìœ„ë¥¼ 0~1ë¡œ)
                confidence = max(0, min(1, (segment.avg_logprob + 1)))
                total_confidence += confidence
                segment_count += 1

            text = "".join(text_parts).strip()
            avg_confidence = total_confidence / max(segment_count, 1)
            processing_time = time.time() - start_time

            # ì„ì‹œ WebM íŒŒì¼ ì‚­ì œ
            try:
                import os
                os.unlink(webm_file_path)
            except Exception as cleanup_error:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {cleanup_error}")

            if text:
                result = TranscriptionResult(
                    text=text,
                    confidence=avg_confidence,
                    is_final=audio_chunk.is_final,
                    timestamp=audio_chunk.timestamp,
                    processing_time=processing_time
                )

                logger.debug(f"WebM ì „ì‚¬ ì™„ë£Œ: '{text}' (ì‹ ë¢°ë„: {avg_confidence:.3f}, "
                           f"ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ)")

                return result

        except Exception as e:
            logger.error(f"WebM ì „ì‚¬ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒì‹œì—ë„ ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                import os
                os.unlink(webm_file_path)
            except:
                pass

        return None

    async def process_stream(self) -> AsyncGenerator[TranscriptionResult, None]:
        """
        ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë° ê²°ê³¼ ìƒì„±

        Yields:
            TranscriptionResult: ì „ì‚¬ ê²°ê³¼
        """
        if not self.is_initialized:
            await self.initialize()

        logger.info("ğŸ¤ ìŠ¤íŠ¸ë¦¬ë° STT ì‹œì‘")

        try:
            while True:
                try:
                    # ì˜¤ë””ì˜¤ ì²­í¬ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
                    chunk = await asyncio.wait_for(
                        self.audio_queue.get(),
                        timeout=5.0
                    )

                    # ì „ì‚¬ ì²˜ë¦¬
                    result = await self.transcribe_chunk(chunk)
                    if result:
                        yield result

                except asyncio.TimeoutError:
                    # íƒ€ì„ì•„ì›ƒì€ ì •ìƒ ë™ì‘ (ìƒˆ ì²­í¬ ëŒ€ê¸°)
                    continue
                except Exception as e:
                    logger.error(f"ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue

        except asyncio.CancelledError:
            logger.info("ìŠ¤íŠ¸ë¦¬ë° STT ì¤‘ì§€ë¨")
        except Exception as e:
            logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ í†µê³„ ë°˜í™˜"""
        return {
            "model_size": self.model_size,
            "device": self.device,
            "compute_type": self.compute_type,
            "is_initialized": self.is_initialized,
            "sample_rate": self.sample_rate,
            "chunk_duration": self.chunk_duration,
            "queue_size": self.audio_queue.qsize() if hasattr(self.audio_queue, 'qsize') else 0
        }

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("STT ì„œë¹„ìŠ¤ ì •ë¦¬ ì¤‘...")
        if self.model:
            del self.model
        self.model = None
        self.is_initialized = False
        logger.info("âœ… STT ì„œë¹„ìŠ¤ ì •ë¦¬ ì™„ë£Œ")

# ì „ì—­ STT ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
streaming_stt_service = StreamingSTTService(
    model_size="base",  # base ëª¨ë¸ë¡œ ì‹œì‘ (ì†ë„ì™€ ì •í™•ë„ ê· í˜•)
    device="auto",
    compute_type="int8"  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
)