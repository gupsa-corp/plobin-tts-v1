#!/usr/bin/env python3
"""
ì›¹ ê¸°ë°˜ ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ
Speech-to-Text + Text-to-Speech ì‹¤ì‹œê°„ ëŒ€í™”
"""

import os
import sys
import asyncio
import tempfile
import warnings
import json
import uuid
import subprocess
from pathlib import Path
from typing import Optional, List
import base64

warnings.filterwarnings("ignore")

# Add MeloTTS to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'MeloTTS'))

from fastapi import FastAPI, File, UploadFile, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import uvicorn

# TTS ê´€ë ¨ ì„í¬íŠ¸
try:
    import torch
    from melo.api import TTS
    TTS_AVAILABLE = True
except ImportError:
    TTS_AVAILABLE = False

# STT ê´€ë ¨ ì„í¬íŠ¸ (Whisperë§Œ - WebM ì§ì ‘ ì²˜ë¦¬)
try:
    import whisper
    STT_AVAILABLE = True
except ImportError:
    STT_AVAILABLE = False

# ì˜¤ë””ì˜¤ ë³€í™˜ í•¨ìˆ˜
def convert_wav_to_webm(wav_path: str) -> str:
    """WAV íŒŒì¼ì„ WebMìœ¼ë¡œ ë³€í™˜"""
    webm_path = wav_path.replace('.wav', '.webm')

    try:
        # ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ WAV â†’ WebM ë³€í™˜
        subprocess.run([
            'ffmpeg', '-i', wav_path,
            '-c:a', 'libopus',  # Opus ì˜¤ë””ì˜¤ ì½”ë± ì‚¬ìš©
            '-b:a', '64k',      # 64kbps ë¹„íŠ¸ë ˆì´íŠ¸
            '-y',               # ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°
            webm_path
        ], check=True, capture_output=True)

        # ì›ë³¸ WAV íŒŒì¼ ì‚­ì œ
        if os.path.exists(wav_path):
            os.unlink(wav_path)

        return webm_path

    except subprocess.CalledProcessError as e:
        # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ WAV ë°˜í™˜
        print(f"âš ï¸ WebM ë³€í™˜ ì‹¤íŒ¨, WAV íŒŒì¼ ìœ ì§€: {e}")
        return wav_path
    except Exception as e:
        print(f"âš ï¸ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return wav_path

# ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ ì„í¬íŠ¸
try:
    from streaming_stt_service import streaming_stt_service, TranscriptionResult
    STREAMING_STT_AVAILABLE = True
except ImportError:
    STREAMING_STT_AVAILABLE = False
    print("âŒ ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

# ìë™ ëŒ€í™” ê´€ë ¨ ì„í¬íŠ¸
from auto_chat_manager import auto_chat_manager
from conversation_patterns import conversation_patterns

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ API",
    description="Speech-to-Text + Text-to-Speech ì‹¤ì‹œê°„ ëŒ€í™” ì‹œìŠ¤í…œ",
    version="2.0.0",
    docs_url="/docs",  # Swagger UI ê²½ë¡œ
    redoc_url="/redoc"  # ReDoc ê²½ë¡œ
)

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/static", StaticFiles(directory="static"), name="static")

# ì „ì—­ ë³€ìˆ˜
tts_model = None
stt_model = None
connected_clients = []

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class TTSRequest(BaseModel):
    text: str
    language: str = "KR"
    speed: float = 2.0
    device: str = "auto"

class TTSResponse(BaseModel):
    success: bool
    audio_url: Optional[str] = None
    error: Optional[str] = None

class STTResponse(BaseModel):
    success: bool
    text: Optional[str] = None
    error: Optional[str] = None

class ChatMessage(BaseModel):
    type: str  # "user", "system"
    text: str
    timestamp: str
    audio_url: Optional[str] = None

# ìë™ ëŒ€í™” ê´€ë ¨ ëª¨ë¸
class AutoChatStartRequest(BaseModel):
    theme: str = "casual"
    interval: int = 30  # ì´ˆ ë‹¨ìœ„

class AutoChatResponse(BaseModel):
    success: bool
    session_id: Optional[str] = None
    message: Optional[str] = None
    error: Optional[str] = None

class AutoChatUpdateRequest(BaseModel):
    theme: Optional[str] = None
    interval: Optional[int] = None

# ëª¨ë¸ ì´ˆê¸°í™”
async def initialize_models():
    """TTSì™€ STT ëª¨ë¸ ì´ˆê¸°í™”"""
    global tts_model, stt_model

    if TTS_AVAILABLE:
        try:
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            tts_model = TTS(language="KR", device=device)
            print(f"âœ… TTS ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {device})")
        except Exception as e:
            print(f"âŒ TTS ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    if STT_AVAILABLE:
        try:
            # ë” ë‚˜ì€ í•œêµ­ì–´ ì§€ì›ì„ ìœ„í•´ medium ëª¨ë¸ ì‚¬ìš© (ë‹¤ìš´ë¡œë“œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ baseë¡œ ì„ì‹œ ì„¤ì •)
            stt_model = whisper.load_model("base")
            print("âœ… STT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (medium - í•œêµ­ì–´ ìµœì í™”)")
        except Exception as e:
            print(f"âŒ STT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ì‹œ ëª¨ë¸ ì´ˆê¸°í™”"""
    await initialize_models()

    # ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    if STREAMING_STT_AVAILABLE:
        try:
            await streaming_stt_service.initialize()
            print("âœ… ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # static ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("static/audio", exist_ok=True)
    os.makedirs("templates", exist_ok=True)

@app.get("/", response_class=HTMLResponse)
async def get_index():
    """ë©”ì¸ í˜ì´ì§€"""
    html_file = "templates/index.html"
    if os.path.exists(html_file):
        with open(html_file, "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    else:
        # ê¸°ë³¸ HTML ë°˜í™˜
        return HTMLResponse(content="""
        <!DOCTYPE html>
        <html>
        <head>
            <title>ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ</title>
            <meta charset="utf-8">
        </head>
        <body>
            <h1>ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ</h1>
            <p>ì›¹ UIê°€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.</p>
            <p><a href="/docs">API ë¬¸ì„œ ë³´ê¸° (Swagger)</a></p>
        </body>
        </html>
        """)

@app.post("/api/tts", response_model=TTSResponse,
          summary="í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜",
          description="ì…ë ¥ëœ í…ìŠ¤íŠ¸ë¥¼ ìŒì„± íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
async def text_to_speech(request: TTSRequest):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    global tts_model

    if not TTS_AVAILABLE or not tts_model:
        raise HTTPException(status_code=503, detail="TTS ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    try:
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if request.device == 'auto':
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            device = request.device

        # í•„ìš”ì‹œ ëª¨ë¸ ì¬ë¡œë“œ
        if hasattr(tts_model, 'device') and str(tts_model.device) != device:
            tts_model = TTS(language=request.language, device=device)

        # ì„ì‹œ WAV íŒŒì¼ ìƒì„±
        wav_filename = f"audio_{uuid.uuid4().hex}.wav"
        wav_path = f"static/audio/{wav_filename}"

        # TTS ë³€í™˜ (WAVë¡œ ìƒì„±)
        tts_model.tts_to_file(
            text=request.text,
            speaker_id=0,
            output_path=wav_path,
            speed=request.speed,
            quiet=True
        )

        # WAV â†’ WebM ë³€í™˜
        final_path = convert_wav_to_webm(wav_path)
        final_filename = os.path.basename(final_path)

        return TTSResponse(
            success=True,
            audio_url=f"/static/audio/{final_filename}"
        )

    except Exception as e:
        return TTSResponse(
            success=False,
            error=str(e)
        )

@app.post("/api/stt", response_model=STTResponse,
          summary="WebM ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜",
          description="ì—…ë¡œë“œëœ WebM ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
async def speech_to_text(audio_file: UploadFile = File(...)):
    """WebM ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not STT_AVAILABLE or not stt_model:
        raise HTTPException(status_code=503, detail="STT ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # WebM íŒŒì¼ë§Œ í—ˆìš©
    if not audio_file.filename or not audio_file.filename.lower().endswith('.webm'):
        if not audio_file.content_type or 'webm' not in audio_file.content_type.lower():
            raise HTTPException(status_code=400, detail="WebM í˜•ì‹ì˜ íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤")

    try:
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì½ê¸°
        content = await audio_file.read()

        # íŒŒì¼ í¬ê¸° ê²€ì¦
        if len(content) < 100:
            raise HTTPException(status_code=400, detail="ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤")

        # WebM ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix='.webm') as temp_file:
            temp_file.write(content)
            webm_path = temp_file.name

        # WebM íŒŒì¼ ìœ íš¨ì„± ê²€ì¦
        try:
            with open(webm_path, 'rb') as f:
                header = f.read(32)
                if b'\x1a\x45\xdf\xa3' not in header:  # EBML header í™•ì¸
                    raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ WebM íŒŒì¼ì…ë‹ˆë‹¤")
        except Exception as validation_error:
            if os.path.exists(webm_path):
                os.unlink(webm_path)
            raise HTTPException(status_code=400, detail=f"WebM íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {str(validation_error)}")

        # STT ë³€í™˜ (WebM ì§ì ‘ ì²˜ë¦¬)
        try:
            result = stt_model.transcribe(
                webm_path,
                language="ko",  # í•œêµ­ì–´ ê¸°ë³¸ ì„¤ì •
                initial_prompt="ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”.",  # í•œêµ­ì–´ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
                word_timestamps=True,
                fp16=False,  # ì•ˆì •ì„±ì„ ìœ„í•´ fp16 ë¹„í™œì„±í™”
                temperature=0.0,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ temperature 0
                compression_ratio_threshold=2.4,
                logprob_threshold=-1.0,
                no_speech_threshold=0.6
            )
        except Exception as transcribe_error:
            # ì„ì‹œ WebM íŒŒì¼ ì‚­ì œ
            if os.path.exists(webm_path):
                os.unlink(webm_path)
            raise HTTPException(status_code=500, detail=f"STT ì²˜ë¦¬ ì˜¤ë¥˜: {str(transcribe_error)}")

        # ì„ì‹œ WebM íŒŒì¼ ì‚­ì œ
        if os.path.exists(webm_path):
            os.unlink(webm_path)

        return STTResponse(
            success=True,
            text=result["text"].strip()
        )

    except Exception as e:
        return STTResponse(
            success=False,
            error=str(e)
        )

@app.get("/api/models/status",
         summary="ëª¨ë¸ ìƒíƒœ í™•ì¸",
         description="TTSì™€ STT ëª¨ë¸ì˜ ë¡œë“œ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
async def get_models_status():
    """ëª¨ë¸ ìƒíƒœ í™•ì¸"""
    return {
        "tts_available": TTS_AVAILABLE and tts_model is not None,
        "stt_available": STT_AVAILABLE and stt_model is not None,
        "tts_device": str(getattr(tts_model, 'device', 'unknown')) if tts_model else None,
        "cuda_available": torch.cuda.is_available() if TTS_AVAILABLE else False
    }

@app.get("/api/languages",
         summary="ì§€ì› ì–¸ì–´ ëª©ë¡",
         description="TTSì—ì„œ ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
async def get_supported_languages():
    """ì§€ì› ì–¸ì–´ ëª©ë¡"""
    return {
        "languages": [
            {"code": "KR", "name": "í•œêµ­ì–´"},
            {"code": "EN", "name": "ì˜ì–´ (v1)"},
            {"code": "EN_V2", "name": "ì˜ì–´ (v2)"},
            {"code": "EN_NEWEST", "name": "ì˜ì–´ (v3)"},
            {"code": "ZH", "name": "ì¤‘êµ­ì–´"},
            {"code": "JP", "name": "ì¼ë³¸ì–´"},
            {"code": "FR", "name": "í”„ë‘ìŠ¤ì–´"},
            {"code": "ES", "name": "ìŠ¤í˜ì¸ì–´"}
        ]
    }

@app.get("/api/websocket/info",
         summary="WebSocket ì—”ë“œí¬ì¸íŠ¸ ì •ë³´",
         description="ì‚¬ìš© ê°€ëŠ¥í•œ WebSocket ì—”ë“œí¬ì¸íŠ¸ë“¤ê³¼ ì‚¬ìš©ë²•ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
async def get_websocket_info():
    """WebSocket ì—”ë“œí¬ì¸íŠ¸ ì •ë³´"""
    return {
        "endpoints": [
            {
                "path": "/ws/stt",
                "name": "ê¸°ì¡´ STT (ë°°ì¹˜ ì²˜ë¦¬)",
                "description": "ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ê¸°ì¡´ ë°©ì‹",
                "processing_type": "batch",
                "latency": "2-5ì´ˆ",
                "message_format": {
                    "send": {
                        "type": "audio",
                        "data": "<base64_encoded_audio>",
                        "timestamp": "optional_timestamp"
                    },
                    "receive": {
                        "type": "stt_result",
                        "text": "ë³€í™˜ëœ í…ìŠ¤íŠ¸",
                        "confidence": 0.95,
                        "timestamp": "timestamp"
                    }
                },
                "supported_audio_formats": ["WEBM"]
            },
            {
                "path": "/ws/streaming-stt",
                "name": "ğŸš€ ìŠ¤íŠ¸ë¦¬ë° STT (ì‹¤ì‹œê°„)",
                "description": "Faster Whisper + VAD ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹",
                "processing_type": "streaming_chunks",
                "latency": "200-500ms",
                "features": [
                    "ì‹¤ì‹œê°„ ì²­í¬ ì²˜ë¦¬ (500ms ê°„ê²©)",
                    "Voice Activity Detection (VAD)",
                    "ë¶€ë¶„ ê²°ê³¼ + ìµœì¢… ê²°ê³¼ ë¶„ë¦¬",
                    "4-5ë°° ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„",
                    "50% ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©"
                ],
                "message_format": {
                    "send": {
                        "type": "audio_chunk | start_stream | stop_stream | ping",
                        "data": "<base64_encoded_audio_chunk>",
                        "timestamp": "timestamp",
                        "chunk_id": "unique_id"
                    },
                    "receive_partial": {
                        "type": "partial_result",
                        "text": "ë¶€ë¶„ ê²°ê³¼...",
                        "confidence": 0.85,
                        "is_final": False,
                        "timestamp": 1701943800.123,
                        "processing_time": 0.25
                    },
                    "receive_final": {
                        "type": "final_result",
                        "text": "ìµœì¢… ì™„ì„±ëœ í…ìŠ¤íŠ¸",
                        "confidence": 0.92,
                        "is_final": True,
                        "timestamp": 1701943802.456,
                        "processing_time": 0.18
                    }
                },
                "supported_audio_formats": ["WEBM"],
                "example_js_code": """
// ìŠ¤íŠ¸ë¦¬ë° STT WebSocket ì—°ê²°
const streamingWs = new WebSocket('ws://localhost:6001/ws/streaming-stt');

// ìŠ¤íŠ¸ë¦¼ ì‹œì‘
streamingWs.send(JSON.stringify({
    type: 'start_stream',
    timestamp: new Date().toISOString()
}));

// ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡ (MediaRecorder ì‚¬ìš©)
mediaRecorder.ondataavailable = (event) => {
    if (event.data.size > 0) {
        const reader = new FileReader();
        reader.onload = () => {
            const base64 = btoa(reader.result);
            streamingWs.send(JSON.stringify({
                type: 'audio_chunk',
                data: base64,
                timestamp: new Date().toISOString(),
                chunk_id: Date.now().toString()
            }));
        };
        reader.readAsBinaryString(event.data);
    }
};

// 500msë§ˆë‹¤ ì²­í¬ ìƒì„±
mediaRecorder.start(500);

// ê²°ê³¼ ìˆ˜ì‹ 
streamingWs.onmessage = (event) => {
    const data = JSON.parse(event.data);

    if (data.type === 'partial_result') {
        // ì‹¤ì‹œê°„ ë¶€ë¶„ ê²°ê³¼ í‘œì‹œ
        updatePartialText(data.text, data.confidence);
    } else if (data.type === 'final_result') {
        // ìµœì¢… ê²°ê³¼ í™•ì •
        finalizeTranon(data.text, data.confidence);
    }
};
                """
            },
            {
                "path": "/ws/chat",
                "name": "ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”",
                "description": "STT + TTS + ëŒ€í™” ì‹œìŠ¤í…œ í†µí•©",
                "message_format": {
                    "send": {
                        "type": "audio | auto_chat_start | auto_chat_stop | auto_chat_message",
                        "data": "message_data",
                        "theme": "optional_for_auto_chat",
                        "interval": "optional_for_auto_chat"
                    },
                    "receive": {
                        "type": "user_message | system_response | auto_message_response | error",
                        "text": "ë©”ì‹œì§€ ë‚´ìš©",
                        "audio_url": "ìŒì„± íŒŒì¼ URL (í•´ë‹¹í•˜ëŠ” ê²½ìš°)",
                        "timestamp": "timestamp"
                    }
                },
                "features": [
                    "ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (STT)",
                    "ìŒì„± í•©ì„± (TTS)",
                    "ìë™ ëŒ€í™” ì‹œìŠ¤í…œ",
                    "ë‹¤ì–‘í•œ ëŒ€í™” ì£¼ì œ ì§€ì›"
                ]
            }
        ],
        "performance_comparison": {
            "legacy_stt": {
                "latency": "2-5ì´ˆ",
                "processing": "ë°°ì¹˜",
                "realtime": False
            },
            "streaming_stt": {
                "latency": "200-500ms",
                "processing": "ìŠ¤íŠ¸ë¦¬ë°",
                "realtime": True,
                "speed_improvement": "4-5ë°°"
            }
        },
        "common_message_types": {
            "ping": "ì—°ê²° ìƒíƒœ í™•ì¸ (ëª¨ë“  WebSocketì—ì„œ ì§€ì›)",
            "pong": "pingì— ëŒ€í•œ ì‘ë‹µ"
        },
        "connection_examples": {
            "legacy_stt": "ws://localhost:6001/ws/stt",
            "streaming_stt": "ws://localhost:6001/ws/streaming-stt",
            "chat": "ws://localhost:6001/ws/chat"
        }
    }

# ìë™ ëŒ€í™” API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/api/auto-chat/themes",
         summary="ìë™ ëŒ€í™” ì£¼ì œ ëª©ë¡",
         description="ì‚¬ìš© ê°€ëŠ¥í•œ ìë™ ëŒ€í™” ì£¼ì œë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
async def get_auto_chat_themes():
    """ìë™ ëŒ€í™” ì£¼ì œ ëª©ë¡"""
    themes = conversation_patterns.get_all_themes()
    theme_info = {
        "casual": "ì¼ìƒ ëŒ€í™”",
        "weather": "ë‚ ì”¨ ì´ì•¼ê¸°",
        "educational": "í•™ìŠµ ë„ìš°ë¯¸",
        "entertainment": "ì¬ë¯¸ìˆëŠ” ëŒ€í™”",
        "motivational": "ë™ê¸°ë¶€ì—¬",
        "questions": "ì§ˆë¬¸ê³¼ ë‹µë³€",
        "greeting": "ì¸ì‚¬ë§"
    }

    return {
        "themes": [
            {"code": theme, "name": theme_info.get(theme, theme)}
            for theme in themes
        ]
    }

@app.get("/api/auto-chat/sessions",
         summary="ìë™ ëŒ€í™” ì„¸ì…˜ ì •ë³´",
         description="í˜„ì¬ í™œì„±í™”ëœ ìë™ ëŒ€í™” ì„¸ì…˜ë“¤ì˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
async def get_auto_chat_sessions():
    """ìë™ ëŒ€í™” ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
    return auto_chat_manager.get_all_sessions_info()

@app.get("/api/auto-chat/sessions/{session_id}",
         summary="íŠ¹ì • ìë™ ëŒ€í™” ì„¸ì…˜ ì •ë³´",
         description="íŠ¹ì • ìë™ ëŒ€í™” ì„¸ì…˜ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
async def get_auto_chat_session(session_id: str):
    """íŠ¹ì • ìë™ ëŒ€í™” ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
    session_info = auto_chat_manager.get_session_info(session_id)
    if session_info:
        return session_info
    else:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

# ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¬ë° STT ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/api/streaming-stt/status",
         summary="ìŠ¤íŠ¸ë¦¬ë° STT ì„œë¹„ìŠ¤ ìƒíƒœ",
         description="ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ì˜ ìƒíƒœì™€ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
async def get_streaming_stt_status():
    """ìŠ¤íŠ¸ë¦¬ë° STT ì„œë¹„ìŠ¤ ìƒíƒœ ì¡°íšŒ"""
    if not STREAMING_STT_AVAILABLE:
        raise HTTPException(status_code=503, detail="ìŠ¤íŠ¸ë¦¬ë° STT ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    return streaming_stt_service.get_stats()

@app.post("/api/streaming-stt/test",
          summary="ìŠ¤íŠ¸ë¦¬ë° STT í…ŒìŠ¤íŠ¸",
          description="ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° STTë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
async def test_streaming_stt(audio_file: UploadFile = File(...)):
    """ìŠ¤íŠ¸ë¦¬ë° STT í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸"""
    if not STREAMING_STT_AVAILABLE:
        raise HTTPException(status_code=503, detail="ìŠ¤íŠ¸ë¦¬ë° STT ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    try:
        # ì˜¤ë””ì˜¤ ë°ì´í„° ì½ê¸°
        content = await audio_file.read()

        # ìŠ¤íŠ¸ë¦¬ë° STT ì„œë¹„ìŠ¤ì— ì¶”ê°€
        streaming_stt_service.add_audio_chunk(content, time.time())

        # ì ì‹œ ëŒ€ê¸° í›„ ê²°ê³¼ ìˆ˜ì§‘ (í…ŒìŠ¤íŠ¸ìš©)
        results = []
        timeout = 10  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
        start_time = time.time()

        async for result in streaming_stt_service.process_stream():
            results.append({
                "text": result.text,
                "confidence": result.confidence,
                "is_final": result.is_final,
                "processing_time": result.processing_time
            })

            # ìµœì¢… ê²°ê³¼ê°€ ë‚˜ì˜¤ê±°ë‚˜ íƒ€ì„ì•„ì›ƒë˜ë©´ ì¢…ë£Œ
            if result.is_final or (time.time() - start_time) > timeout:
                break

        return {
            "success": True,
            "results": results,
            "file_info": {
                "filename": audio_file.filename,
                "size": len(content),
                "content_type": audio_file.content_type
            }
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/streaming-stt/compare",
         summary="STT ì„±ëŠ¥ ë¹„êµ",
         description="ê¸°ì¡´ STTì™€ ìŠ¤íŠ¸ë¦¬ë° STTì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.")
async def compare_stt_performance():
    """STT ì„±ëŠ¥ ë¹„êµ ì •ë³´"""
    return {
        "legacy_stt": {
            "name": "OpenAI Whisper (ë°°ì¹˜ ì²˜ë¦¬)",
            "model": "medium",
            "processing_type": "batch",
            "typical_latency": "2-5ì´ˆ",
            "pros": ["ë†’ì€ ì •í™•ë„", "ì•ˆì •ì„±"],
            "cons": ["ë†’ì€ ì§€ì—°ì‹œê°„", "ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¶ˆê°€"]
        },
        "streaming_stt": {
            "name": "Faster Whisper (ìŠ¤íŠ¸ë¦¬ë°)",
            "model": "base",
            "processing_type": "streaming_chunks",
            "typical_latency": "200-500ms",
            "pros": ["ë‚®ì€ ì§€ì—°ì‹œê°„", "ì‹¤ì‹œê°„ í”¼ë“œë°±", "VAD ìµœì í™”", "4-5ë°° ë¹ ë¥¸ ì†ë„", "WebM ì§ì ‘ ì²˜ë¦¬"],
            "cons": ["ì•½ê°„ ë‚®ì€ ì •í™•ë„ (ëª¨ë¸ í¬ê¸°ì— ë”°ë¼)"]
        },
        "performance_metrics": {
            "speed_improvement": "4-5x faster",
            "latency_reduction": "80-90% ê°ì†Œ",
            "memory_usage": "50% ê°ì†Œ",
            "conversion_overhead": "WebM ì§ì ‘ ì²˜ë¦¬ë¡œ ë³€í™˜ ë‹¨ê³„ ì œê±°",
            "realtime_factor": "ìŠ¤íŠ¸ë¦¬ë°ë§Œ ì§€ì›"
        }
    }

# WebSocket ì—°ê²° ê´€ë¦¬
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

manager = ConnectionManager()

# WebSocket STT ì „ìš© ì‘ë‹µ ëª¨ë¸ (Swaggerìš©)
class WebSocketSTTMessage(BaseModel):
    """WebSocket STT ë©”ì‹œì§€ ëª¨ë¸"""
    type: str  # "audio", "text"
    data: Optional[str] = None  # Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° ë˜ëŠ” í…ìŠ¤íŠ¸
    timestamp: Optional[str] = None

# WebSocket STT ê´€ë ¨ ëª¨ë¸ë“¤
class WebSocketSTTResponse(BaseModel):
    """WebSocket STT ì‘ë‹µ ëª¨ë¸"""
    type: str  # "stt_result", "error"
    text: Optional[str] = None  # ë³€í™˜ëœ í…ìŠ¤íŠ¸
    confidence: Optional[float] = None  # ì‹ ë¢°ë„ (0-1)
    error: Optional[str] = None
    timestamp: Optional[str] = None

# ìŠ¤íŠ¸ë¦¬ë° STT ê´€ë ¨ ëª¨ë¸ë“¤
class StreamingSTTRequest(BaseModel):
    """ìŠ¤íŠ¸ë¦¬ë° STT ìš”ì²­ ëª¨ë¸"""
    type: str = "audio_chunk"  # "audio_chunk", "start_stream", "stop_stream", "ping"
    data: Optional[str] = None  # Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„°
    timestamp: Optional[str] = None
    chunk_id: Optional[str] = None

    class Config:
        schema_extra = {
            "example": {
                "type": "audio_chunk",
                "data": "UklGRiQAAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQAAAAA=",
                "timestamp": "2023-12-07T10:30:00.000Z",
                "chunk_id": "1701943800000"
            }
        }

class StreamingSTTPartialResponse(BaseModel):
    """ìŠ¤íŠ¸ë¦¬ë° STT ë¶€ë¶„ ê²°ê³¼ ì‘ë‹µ"""
    type: str = "partial_result"
    text: str
    confidence: float  # 0.0 ~ 1.0
    is_final: bool = False
    timestamp: float
    processing_time: Optional[float] = None

    class Config:
        schema_extra = {
            "example": {
                "type": "partial_result",
                "text": "ì•ˆë…•í•˜ì„¸ìš”",
                "confidence": 0.85,
                "is_final": False,
                "timestamp": 1701943800.123,
                "processing_time": 0.25
            }
        }

class StreamingSTTFinalResponse(BaseModel):
    """ìŠ¤íŠ¸ë¦¬ë° STT ìµœì¢… ê²°ê³¼ ì‘ë‹µ"""
    type: str = "final_result"
    text: str
    confidence: float  # 0.0 ~ 1.0
    is_final: bool = True
    timestamp: float
    processing_time: float

    class Config:
        schema_extra = {
            "example": {
                "type": "final_result",
                "text": "ì•ˆë…•í•˜ì„¸ìš”. ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                "confidence": 0.92,
                "is_final": True,
                "timestamp": 1701943802.456,
                "processing_time": 0.18
            }
        }

class StreamingSTTStatusResponse(BaseModel):
    """ìŠ¤íŠ¸ë¦¬ë° STT ìƒíƒœ ì‘ë‹µ"""
    type: str  # "stream_started", "stream_stopped", "error"
    message: str
    session_id: Optional[str] = None

    class Config:
        schema_extra = {
            "example": {
                "type": "stream_started",
                "message": "ì‹¤ì‹œê°„ STT ìŠ¤íŠ¸ë¦¼ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤",
                "session_id": "session_123"
            }
        }

class STTServiceStats(BaseModel):
    """STT ì„œë¹„ìŠ¤ í†µê³„ ëª¨ë¸"""
    model_size: str
    device: str
    compute_type: str
    is_initialized: bool
    sample_rate: int
    chunk_duration: float
    queue_size: int
    vad_aggressiveness: int

    class Config:
        schema_extra = {
            "example": {
                "model_size": "base",
                "device": "cpu",
                "compute_type": "int8",
                "is_initialized": True,
                "sample_rate": 16000,
                "chunk_duration": 1.0,
                "queue_size": 0,
                "vad_aggressiveness": 3
            }
        }

@app.websocket("/ws/stt")
async def websocket_stt_legacy(websocket: WebSocket):
    """ê¸°ì¡´ STT WebSocket (ë°°ì¹˜ ì²˜ë¦¬ ë°©ì‹)"""
    await manager.connect(websocket)
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
            data = await websocket.receive_text()
            message_data = json.loads(data)

            if message_data["type"] == "audio":
                # ìŒì„± ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                try:
                    if not STT_AVAILABLE or not stt_model:
                        await manager.send_personal_message(json.dumps({
                            "type": "error",
                            "error": "STT ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                            "timestamp": message_data.get("timestamp", "")
                        }), websocket)
                        continue

                    # Base64 ì˜¤ë””ì˜¤ ë””ì½”ë”©
                    audio_data = base64.b64decode(message_data["data"])

                    # WebM ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.webm') as temp_file:
                        temp_file.write(audio_data)
                        webm_path = temp_file.name

                    # STT ë³€í™˜ (WebM ì§ì ‘ ì²˜ë¦¬)
                    result = stt_model.transcribe(
                        webm_path,
                        language="ko",  # í•œêµ­ì–´ ê¸°ë³¸ ì„¤ì •
                        initial_prompt="ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        word_timestamps=True,
                        fp16=False,
                        temperature=0.0,
                        compression_ratio_threshold=2.4,
                        logprob_threshold=-1.0,
                        no_speech_threshold=0.6
                    )
                    transcribed_text = result["text"].strip()

                    # ì‹ ë¢°ë„ ê³„ì‚° (WhisperëŠ” ì„¸ê·¸ë¨¼íŠ¸ë³„ í™•ë¥  ì œê³µ)
                    confidence = 0.0
                    if "segments" in result and result["segments"]:
                        confidence = sum(seg.get("avg_logprob", 0) for seg in result["segments"]) / len(result["segments"])
                        confidence = max(0, min(1, (confidence + 1) / 2))  # -1~0 ë²”ìœ„ë¥¼ 0~1ë¡œ ë³€í™˜

                    # ì„ì‹œ WebM íŒŒì¼ ì‚­ì œ
                    if os.path.exists(webm_path):
                        os.unlink(webm_path)

                    # STT ê²°ê³¼ ì „ì†¡
                    await manager.send_personal_message(json.dumps({
                        "type": "stt_result",
                        "text": transcribed_text,
                        "confidence": round(confidence, 3),
                        "timestamp": message_data.get("timestamp", "")
                    }), websocket)

                except Exception as e:
                    await manager.send_personal_message(json.dumps({
                        "type": "error",
                        "error": f"STT ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                        "timestamp": message_data.get("timestamp", "")
                    }), websocket)

            elif message_data["type"] == "ping":
                # ì—°ê²° ìƒíƒœ í™•ì¸
                await manager.send_personal_message(json.dumps({
                    "type": "pong",
                    "timestamp": message_data.get("timestamp", "")
                }), websocket)

    except WebSocketDisconnect:
        manager.disconnect(websocket)

@app.websocket("/ws/streaming-stt")
async def websocket_streaming_stt(websocket: WebSocket):
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° STT WebSocket (ìƒˆë¡œìš´ ê³ ì„±ëŠ¥ ë²„ì „)

    ìŒì„± ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ì•„ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    Faster Whisper + VAD ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

    **ë©”ì‹œì§€ í˜•ì‹:**
    - ì†¡ì‹ : `{"type": "audio_chunk", "data": "<base64_audio>", "timestamp": "...", "chunk_id": "..."}`
    - ìˆ˜ì‹ : `{"type": "partial_result", "text": "ë¶€ë¶„ ê²°ê³¼", "confidence": 0.95, "is_final": false}`
    - ìˆ˜ì‹ : `{"type": "final_result", "text": "ìµœì¢… ê²°ê³¼", "confidence": 0.98, "is_final": true}`

    **ì§€ì› ì˜¤ë””ì˜¤ í˜•ì‹:** WebM (Opus ì½”ë±)
    """
    await manager.connect(websocket)
    print(f"ğŸ¤ ì‹¤ì‹œê°„ STT í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {websocket.client}")

    if not STREAMING_STT_AVAILABLE:
        await manager.send_personal_message(json.dumps({
            "type": "error",
            "error": "ì‹¤ì‹œê°„ STT ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        }), websocket)
        return

    try:
        # ìŠ¤íŠ¸ë¦¬ë° STT ì²˜ë¦¬ íƒœìŠ¤í¬ ì‹œì‘
        processing_task = asyncio.create_task(
            process_streaming_stt(websocket)
        )

        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
            data = await websocket.receive_text()
            message_data = json.loads(data)

            if message_data["type"] == "audio_chunk":
                try:
                    # Base64 ì˜¤ë””ì˜¤ ë””ì½”ë”©
                    audio_data = base64.b64decode(message_data["data"])
                    timestamp = message_data.get("timestamp", time.time())

                    # ìŠ¤íŠ¸ë¦¬ë° STT ì„œë¹„ìŠ¤ì— ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€
                    streaming_stt_service.add_audio_chunk(audio_data, timestamp)

                except Exception as e:
                    await manager.send_personal_message(json.dumps({
                        "type": "error",
                        "error": f"ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                        "timestamp": message_data.get("timestamp", "")
                    }), websocket)

            elif message_data["type"] == "start_stream":
                # ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì‹ í˜¸
                await manager.send_personal_message(json.dumps({
                    "type": "stream_started",
                    "message": "ì‹¤ì‹œê°„ STT ìŠ¤íŠ¸ë¦¼ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤"
                }), websocket)

            elif message_data["type"] == "stop_stream":
                # ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ ì‹ í˜¸
                processing_task.cancel()
                await manager.send_personal_message(json.dumps({
                    "type": "stream_stopped",
                    "message": "ì‹¤ì‹œê°„ STT ìŠ¤íŠ¸ë¦¼ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤"
                }), websocket)
                break

            elif message_data["type"] == "ping":
                # ì—°ê²° ìƒíƒœ í™•ì¸
                await manager.send_personal_message(json.dumps({
                    "type": "pong",
                    "timestamp": message_data.get("timestamp", "")
                }), websocket)

    except WebSocketDisconnect:
        print("ğŸ”Œ ì‹¤ì‹œê°„ STT í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ")
        if 'processing_task' in locals():
            processing_task.cancel()
        manager.disconnect(websocket)
    except Exception as e:
        print(f"âŒ ì‹¤ì‹œê°„ STT WebSocket ì˜¤ë¥˜: {e}")
        if 'processing_task' in locals():
            processing_task.cancel()

async def process_streaming_stt(websocket: WebSocket):
    """ì‹¤ì‹œê°„ STT ê²°ê³¼ ì²˜ë¦¬ ë° ì „ì†¡"""
    try:
        async for result in streaming_stt_service.process_stream():
            # ê²°ê³¼ë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡
            response = {
                "type": "final_result" if result.is_final else "partial_result",
                "text": result.text,
                "confidence": round(result.confidence, 3),
                "is_final": result.is_final,
                "timestamp": result.timestamp,
                "processing_time": round(result.processing_time, 3)
            }

            await manager.send_personal_message(
                json.dumps(response, ensure_ascii=False),
                websocket
            )

    except asyncio.CancelledError:
        print("ğŸ›‘ ì‹¤ì‹œê°„ STT ì²˜ë¦¬ íƒœìŠ¤í¬ ì·¨ì†Œë¨")
    except Exception as e:
        print(f"âŒ ì‹¤ì‹œê°„ STT ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        await manager.send_personal_message(json.dumps({
            "type": "error",
            "error": f"STT ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
        }), websocket)

@app.websocket("/ws/chat")
async def websocket_chat(websocket: WebSocket):
    """ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™” WebSocket"""
    await manager.connect(websocket)
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
            data = await websocket.receive_text()
            message_data = json.loads(data)

            if message_data["type"] == "audio":
                # ìŒì„± ë°ì´í„° ì²˜ë¦¬ (Base64 ë””ì½”ë”© -> STT -> ì‘ë‹µ ìƒì„± -> TTS)
                try:
                    # Base64 ì˜¤ë””ì˜¤ ë””ì½”ë”©
                    audio_data = base64.b64decode(message_data["data"])

                    # STT ì²˜ë¦¬
                    if STT_AVAILABLE and stt_model:
                        # WebM ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.webm') as temp_file:
                            temp_file.write(audio_data)
                            webm_path = temp_file.name

                        # STT ë³€í™˜ (WebM ì§ì ‘ ì²˜ë¦¬)
                        result = stt_model.transcribe(
                            webm_path,
                            language="ko",  # í•œêµ­ì–´ ê¸°ë³¸ ì„¤ì •
                            initial_prompt="ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                            word_timestamps=True,
                            fp16=False,
                            temperature=0.0,
                            compression_ratio_threshold=2.4,
                            logprob_threshold=-1.0,
                            no_speech_threshold=0.6
                        )
                        user_text = result["text"].strip()

                        # ì„ì‹œ WebM íŒŒì¼ ì‚­ì œ
                        if os.path.exists(webm_path):
                            os.unlink(webm_path)

                        # ì‚¬ìš©ì ë©”ì‹œì§€ ì „ì†¡
                        await manager.send_personal_message(json.dumps({
                            "type": "user_message",
                            "text": user_text,
                            "timestamp": message_data.get("timestamp", "")
                        }), websocket)

                        # ìë™ ëŒ€í™” ë§¤ë‹ˆì €ì— ì‚¬ìš©ì ì…ë ¥ ì•Œë¦¼
                        await auto_chat_manager.handle_user_input(websocket, user_text)

                        # ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„± (ì‹¤ì œë¡œëŠ” AI ëª¨ë¸ ì—°ë™ ê°€ëŠ¥)
                        response_text = generate_response(user_text)

                        # TTS ë³€í™˜
                        if TTS_AVAILABLE and tts_model:
                            wav_filename = f"audio_{uuid.uuid4().hex}.wav"
                            wav_path = f"static/audio/{wav_filename}"

                            tts_model.tts_to_file(
                                text=response_text,
                                speaker_id=0,
                                output_path=wav_path,
                                speed=2.0,
                                quiet=True
                            )

                            # WAV â†’ WebM ë³€í™˜
                            audio_path = convert_wav_to_webm(wav_path)
                            audio_filename = os.path.basename(audio_path)

                            # ì‹œìŠ¤í…œ ì‘ë‹µ ì „ì†¡
                            await manager.send_personal_message(json.dumps({
                                "type": "system_response",
                                "text": response_text,
                                "audio_url": f"/static/audio/{audio_filename}",
                                "timestamp": message_data.get("timestamp", "")
                            }), websocket)

                except Exception as e:
                    await manager.send_personal_message(json.dumps({
                        "type": "error",
                        "message": f"ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
                    }), websocket)

            elif message_data["type"] == "auto_chat_start":
                # ìë™ ëŒ€í™” ì‹œì‘ ìš”ì²­
                try:
                    theme = message_data.get("theme", "casual")
                    interval = message_data.get("interval", 30)

                    session_id = await auto_chat_manager.start_auto_chat(websocket, theme, interval)

                    await manager.send_personal_message(json.dumps({
                        "type": "auto_chat_started",
                        "session_id": session_id,
                        "theme": theme,
                        "interval": interval,
                        "message": "ìë™ ëŒ€í™”ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
                    }), websocket)

                except Exception as e:
                    await manager.send_personal_message(json.dumps({
                        "type": "error",
                        "message": f"ìë™ ëŒ€í™” ì‹œì‘ ì˜¤ë¥˜: {str(e)}"
                    }), websocket)

            elif message_data["type"] == "auto_chat_stop":
                # ìë™ ëŒ€í™” ì¤‘ì§€ ìš”ì²­
                try:
                    stopped = await auto_chat_manager.stop_auto_chat_for_websocket(websocket)

                    await manager.send_personal_message(json.dumps({
                        "type": "auto_chat_stopped",
                        "message": "ìë™ ëŒ€í™”ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤." if stopped else "í™œì„± ìë™ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤."
                    }), websocket)

                except Exception as e:
                    await manager.send_personal_message(json.dumps({
                        "type": "error",
                        "message": f"ìë™ ëŒ€í™” ì¤‘ì§€ ì˜¤ë¥˜: {str(e)}"
                    }), websocket)

            elif message_data["type"] == "auto_chat_message":
                # ìë™ ëŒ€í™” ë©”ì‹œì§€ë¥¼ TTSë¡œ ë³€í™˜
                try:
                    text = message_data.get("text", "")
                    if text and TTS_AVAILABLE and tts_model:
                        wav_filename = f"audio_{uuid.uuid4().hex}.wav"
                        wav_path = f"static/audio/{wav_filename}"

                        tts_model.tts_to_file(
                            text=text,
                            speaker_id=0,
                            output_path=wav_path,
                            speed=2.0,
                            quiet=True
                        )

                        # WAV â†’ WebM ë³€í™˜
                        audio_path = convert_wav_to_webm(wav_path)
                        audio_filename = os.path.basename(audio_path)

                        # ìë™ ëŒ€í™” ë©”ì‹œì§€ë¡œ ì „ì†¡
                        await manager.send_personal_message(json.dumps({
                            "type": "auto_message_response",
                            "text": text,
                            "audio_url": f"/static/audio/{audio_filename}",
                            "timestamp": message_data.get("timestamp", ""),
                            "session_id": message_data.get("session_id", ""),
                            "theme": message_data.get("theme", "casual")
                        }), websocket)

                except Exception as e:
                    await manager.send_personal_message(json.dumps({
                        "type": "error",
                        "message": f"ìë™ ëŒ€í™” TTS ì˜¤ë¥˜: {str(e)}"
                    }), websocket)

    except WebSocketDisconnect:
        # ì—°ê²°ì´ ëŠì–´ì§ˆ ë•Œ ìë™ ëŒ€í™”ë„ ì •ë¦¬
        await auto_chat_manager.stop_auto_chat_for_websocket(websocket)
        manager.disconnect(websocket)


def generate_response(user_text: str) -> str:
    """ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„± (ì¶”í›„ AI ëª¨ë¸ë¡œ í™•ì¥ ê°€ëŠ¥)"""
    user_text = user_text.lower()

    if "ì•ˆë…•" in user_text or "hello" in user_text:
        return "ì•ˆë…•í•˜ì„¸ìš”! ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤."
    elif "ë‚ ì”¨" in user_text or "weather" in user_text:
        return "ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì¢‹ë„¤ìš”!"
    elif "ì´ë¦„" in user_text or "name" in user_text:
        return "ì €ëŠ” ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤."
    elif "ì‹œê°„" in user_text or "time" in user_text:
        import datetime
        now = datetime.datetime.now()
        return f"í˜„ì¬ ì‹œê°„ì€ {now.strftime('%Hì‹œ %Më¶„')}ì…ë‹ˆë‹¤."
    else:
        return "ë„¤, ì˜ ë“¤ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”."

# ê°œë°œ ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸš€ ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ ì›¹ ì„œë²„ ì‹œì‘...")
    print(f"TTS ì§€ì›: {'Yes' if TTS_AVAILABLE else 'No'}")
    print(f"STT ì§€ì›: {'Yes' if STT_AVAILABLE else 'No'}")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:6001/docs")
    print("ğŸŒ ì›¹ ì•±: http://localhost:6001")

    uvicorn.run(app, host="0.0.0.0", port=6001)